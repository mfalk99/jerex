{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jinja2\n",
    "import json\n",
    "import jsonlines\n",
    "\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPES_FILE = \"./data/datasets/docred/types.json\"\n",
    "GT_TRAIN_FILE = \"./data/datasets/docred/train_annotated.json\"\n",
    "PERT_TRAIN_FILE = \"./data/datasets/docred/train_annotated_perturbed.json\"\n",
    "REMOVED_RELS_FILE = \"./data/datasets/docred/train_annotated_removed_rels.json\"\n",
    "SCORES_FILE = \"./influence_analysis/scores/rel_loss_perturbed_ckpt15.jsonl\"\n",
    "\n",
    "TEMPLATE_FILE_DIR = \"./influence_analysis/templates\"\n",
    "TEMPLATE_FILENAME = \"analyse.html\"\n",
    "\n",
    "OUTPUT_FILE = \"./influence_analysis/analyse_rel_loss.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TYPES_FILE, \"r\") as fd:\n",
    "    rel_types = json.load(fd)\n",
    "    rel_types = rel_types[\"relations\"]\n",
    "\n",
    "with open(GT_TRAIN_FILE, \"r\") as fd:\n",
    "    gt_train_docs = json.load(fd)\n",
    "\n",
    "with open(PERT_TRAIN_FILE, \"r\") as fd:\n",
    "    pert_train_docs = json.load(fd)\n",
    "\n",
    "with open(REMOVED_RELS_FILE, \"r\") as fd:\n",
    "    removed_rels = json.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scores(file):\n",
    "    scores = []\n",
    "    \n",
    "    with jsonlines.open(file) as rel_loss_reader:\n",
    "        for doc_id, data in enumerate(rel_loss_reader):\n",
    "            for rel in data:\n",
    "                entry = copy(rel)\n",
    "                entry['doc_id'] = doc_id\n",
    "                scores.append(entry)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_perturbed(rel):\n",
    "    doc_id = rel['doc_id']\n",
    "    head_id, tail_id = rel['entity_pair']\n",
    "    doc = removed_rels[doc_id]\n",
    "    \n",
    "    for r in doc:\n",
    "        if r['h'] == head_id and r['t'] == tail_id:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# get the gt rel (from the perturbed dataset)\n",
    "def get_gt_rel(rel):\n",
    "    doc_id = rel[\"doc_id\"]\n",
    "    head_id, tail_id = rel[\"entity_pair\"]\n",
    "    doc = gt_train_docs[doc_id]\n",
    "\n",
    "    for r in doc[\"labels\"]:\n",
    "        if r[\"h\"] == head_id and r[\"t\"] == tail_id:\n",
    "            return r[\"r\"]\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_text_html(doc, rel):\n",
    "    sents = doc[\"sents\"]\n",
    "    \n",
    "    mentions = []\n",
    "    head_entity_id, tail_entity_id = rel[\"entity_pair\"]\n",
    "    \n",
    "    h_or_t = \"h\"\n",
    "    head_entity_type = doc[\"vertexSet\"][head_entity_id][0][\"type\"]\n",
    "    for mention in doc[\"vertexSet\"][head_entity_id]:\n",
    "        start, end = mention[\"pos\"]\n",
    "        sent_id = mention[\"sent_id\"]\n",
    "        mentions.append([start, end, h_or_t, sent_id])\n",
    "\n",
    "    h_or_t = \"t\"\n",
    "    tail_entity_type = doc[\"vertexSet\"][tail_entity_id][0][\"type\"]\n",
    "    for mention in doc[\"vertexSet\"][tail_entity_id]:\n",
    "        start, end = mention[\"pos\"]\n",
    "        sent_id = mention[\"sent_id\"]\n",
    "        mentions.append([start, end, h_or_t, sent_id])\n",
    "\n",
    "\n",
    "    head_tag = '<span class=\"head\"><span class=\"type\">%s</span>' % head_entity_type\n",
    "    tail_tag = '<span class=\"tail\"><span class=\"type\">%s</span>' % tail_entity_type\n",
    "\n",
    "    for mention in mentions:\n",
    "        start, end, h_or_t, sent_id = mention\n",
    "        tokens = sents[sent_id]\n",
    "        tag = head_tag if h_or_t == \"h\" else tail_tag\n",
    "        tokens[start] = tag + tokens[start]\n",
    "        tokens[end - 1] = tokens[end - 1] + \"</span>\"\n",
    "\n",
    "    html = [\" \".join(t) for t in sents]\n",
    "    html = \" \".join(html)\n",
    "    \n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_template(results, template_dir=TEMPLATE_FILE_DIR, template_name=TEMPLATE_FILENAME, output_file=OUTPUT_FILE):\n",
    "    templateLoader = jinja2.FileSystemLoader(template_dir)\n",
    "    templateEnv = jinja2.Environment(loader=templateLoader)\n",
    "    template = templateEnv.get_template(template_name)\n",
    "    output = template.render(results=results)\n",
    "    \n",
    "    with open(output_file, \"w\") as fd:\n",
    "        fd.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = load_scores(SCORES_FILE)\n",
    "scores = sorted(scores, key=lambda d: d[\"loss\"], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for rel in scores[:50]:\n",
    "    doc = pert_train_docs[rel[\"doc_id\"]]\n",
    "    \n",
    "    text_html = build_text_html(doc, rel)\n",
    "    is_perturbed_rel = is_perturbed(rel)\n",
    "    gt_rel = get_gt_rel(rel)\n",
    "\n",
    "    pred_rels = [(rel, \"%.4f\" % score ) for rel, score in rel[\"preds\"].items()]\n",
    "\n",
    "    c = \"\"\n",
    "    if is_perturbed_rel and len(pred_rels) != 0:\n",
    "        c = \"pert-rel-found\"\n",
    "    elif is_perturbed_rel and len(pred_rels) == 0:\n",
    "        c = \"pert-rel-not-found\"\n",
    "    elif len(pred_rels) != 0 and gt_rel is None:\n",
    "        c = \"pred-rel-but-not-gt\"\n",
    "\n",
    "    pred_rels = \"<br>\".join({f\"{p[0]} (confidence: {p[1]})\" for p in pred_rels})\n",
    "\n",
    "    results.append({\n",
    "        \"doc_id\": rel[\"doc_id\"],\n",
    "        \"text\": text_html,\n",
    "        \"is_perturbed\": is_perturbed_rel,\n",
    "        \"gt_rel\": \"None\" if gt_rel is None else rel_types[gt_rel][\"verbose\"],\n",
    "        \"pred_rels\": \"None\" if pred_rels == \"\" else pred_rels,\n",
    "        \"c\": c,\n",
    "        \"score\": rel[\"loss\"]\n",
    "    })\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_template(results=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('jerex')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89162253f7923f6dd462dbdd48dd8d51abdc110a06081ad1ec0e3ffad7b96664"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
